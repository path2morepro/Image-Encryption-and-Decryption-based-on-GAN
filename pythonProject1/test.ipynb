{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def plot_pixel_correlation(img_array, direction, filename, folder_path):\n",
    "    # 计算并绘制相关性散点图\n",
    "    if direction == 'horizontal':\n",
    "        original = img_array[:, :-1].flatten()\n",
    "        shifted = img_array[:, 1:].flatten()\n",
    "    elif direction == 'vertical':\n",
    "        original = img_array[:-1, :].flatten()\n",
    "        shifted = img_array[1:, :].flatten()\n",
    "    elif direction == 'diagonal':\n",
    "        original = img_array[:-1, :-1].flatten()\n",
    "        shifted = img_array[1:, 1:].flatten()\n",
    "\n",
    " \n",
    "    plt.figure()\n",
    "    plt.scatter(original, shifted, alpha=0.5, s=0.5)  # s 控制点的大小，alpha 控制点的透明度\n",
    "    plt.title(f'{direction.capitalize()} Pixel Correlation')\n",
    "    plt.xlabel('Pixel Value at Position (n)')\n",
    "    plt.ylabel('Pixel Value at Position (n+1)')\n",
    "    plt.grid(True)  # 添加网格线\n",
    "    plt.xlim([0, 255])\n",
    "    plt.ylim([0, 255])\n",
    "    # 保存图像\n",
    "    analysis_filename = f'{direction}_correlation_{filename}.png'\n",
    "    plt.savefig(os.path.join(folder_path, analysis_filename))\n",
    "    plt.close()\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# 创建一个示例图像数组\n",
    "\n",
    "# 设置文件名和保存路径\n",
    "folder_path = './correlation_plots'\n",
    "file_name1 = 'test3.png'\n",
    "\n",
    "\n",
    "image1 = Image.open(folder_path + '\\\\' + file_name1)\n",
    "\n",
    "\n",
    "# 将图像转换为 NumPy 数组\n",
    "img_array1 = np.asarray(image1)\n",
    "\n",
    "# 确保保存路径存在\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "h1 = plot_pixel_correlation(img_array1, 'horizontal', file_name1, folder_path)\n",
    "v1 = plot_pixel_correlation(img_array1, 'vertical', file_name1, folder_path)\n",
    "d1 = plot_pixel_correlation(img_array1, 'diagonal', file_name1, folder_path)\n",
    "\n",
    "\n",
    "# pad_width = len(h1[1]) - len(d1[1])\n",
    "# padding_d1 = np.pad(d1, ((0,0),(0, pad_width)),'constant',constant_values = 0)\n",
    "# # print(padding_d1.shape)\n",
    "# # print(h1.shape)\n",
    "\n",
    "# h2 = plot_pixel_correlation(img_array2, 'horizontal', file_name2, folder_path)\n",
    "# v2 = plot_pixel_correlation(img_array2, 'vertical', file_name2, folder_path)\n",
    "# d2 = plot_pixel_correlation(img_array2, 'diagonal', file_name2, folder_path)\n",
    "# pad_width = len(h2[1]) - len(d2[1])\n",
    "# padding_d2 = np.pad(d2, ((0,0),(0, pad_width)),'constant',constant_values = 0)\n",
    "\n",
    "\n",
    "# pc1 = np.vstack((h1,v1,padding_d1))\n",
    "# pc2 = np.vstack((h2,v2,padding_d2))\n",
    "\n",
    "# print(pc1.shape)\n",
    "# print\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\崔庆轩喜欢摆\\AppData\\Local\\Temp\\ipykernel_19292\\3449724755.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pc1 = torch.tensor(pc1).clone().detach()\n",
      "C:\\Users\\崔庆轩喜欢摆\\AppData\\Local\\Temp\\ipykernel_19292\\3449724755.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pc2 = torch.tensor(pc2).clone().detach()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4116.732421875"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "pc1 = torch.tensor(pc1).clone().detach()\n",
    "pc2 = torch.tensor(pc2).clone().detach()\n",
    "\n",
    "MSE_loss = nn.MSELoss()\n",
    "loss = MSE_loss(pc1.float(), pc2.float())\n",
    "loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4116.732421875"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "def pixel_correlation(img_array):\n",
    "\n",
    "    h_original = img_array[:, :-1].flatten()\n",
    "    h_shifted = img_array[:, 1:].flatten()\n",
    "\n",
    "    v_original = img_array[:-1, :].flatten()\n",
    "    v_shifted = img_array[1:, :].flatten()\n",
    "\n",
    "    d_original = img_array[:-1, :-1].flatten()\n",
    "    d_shifted = img_array[1:, 1:].flatten()\n",
    "\n",
    "\n",
    "    h = np.vstack((h_original,h_shifted))\n",
    "    d = np.vstack((d_original,d_shifted))\n",
    "    v = np.vstack((v_original,v_shifted))\n",
    "\n",
    "    pad_width = len(h[1]) - len(d[1])\n",
    "    padding_d = np.pad(d, ((0,0),(0, pad_width)),'constant',constant_values = 0)      \n",
    "\n",
    "    pixel_corrlation = np.vstack((h,v,padding_d))\n",
    "    pixel_corrlation = torch.tensor(pixel_corrlation)\n",
    "    return pixel_corrlation.clone().detach()\n",
    "\n",
    "pc1 = pixel_correlation(img_array1)\n",
    "pc2 = pixel_correlation(img_array2)\n",
    "\n",
    "loss = MSE_loss(pc1.float(), pc2.float())\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(369, 369, 4)\n",
      "[[[ 28  28  28 255]\n",
      "  [ 24  24  24 255]\n",
      "  [ 21  21  21 255]\n",
      "  ...\n",
      "  [ 18  18  18 255]\n",
      "  [ 22  22  22 255]\n",
      "  [ 23  23  23 255]]\n",
      "\n",
      " [[ 22  22  22 255]\n",
      "  [ 21  21  21 255]\n",
      "  [ 20  20  20 255]\n",
      "  ...\n",
      "  [ 15  15  15 255]\n",
      "  [ 18  18  18 255]\n",
      "  [ 16  16  16 255]]\n",
      "\n",
      " [[ 22  22  22 255]\n",
      "  [ 18  18  18 255]\n",
      "  [ 15  15  15 255]\n",
      "  ...\n",
      "  [ 19  19  19 255]\n",
      "  [ 10  10  10 255]\n",
      "  [ 12  12  12 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 22  22  22 255]\n",
      "  [ 17  17  17 255]\n",
      "  [ 13  13  13 255]\n",
      "  ...\n",
      "  [  9   9   9 255]\n",
      "  [ 15  15  15 255]\n",
      "  [ 18  18  18 255]]\n",
      "\n",
      " [[ 28  28  28 255]\n",
      "  [ 21  21  21 255]\n",
      "  [ 15  15  15 255]\n",
      "  ...\n",
      "  [ 11  11  11 255]\n",
      "  [ 17  17  17 255]\n",
      "  [ 23  23  23 255]]\n",
      "\n",
      " [[ 35  35  35 255]\n",
      "  [ 25  25  25 255]\n",
      "  [ 16  16  16 255]\n",
      "  ...\n",
      "  [ 15  15  15 255]\n",
      "  [ 19  19  19 255]\n",
      "  [ 26  26  26 255]]]\n"
     ]
    }
   ],
   "source": [
    "print(img_array1.shape)\n",
    "print(img_array1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
